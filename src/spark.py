# -*- coding: utf-8 -*-
"""Spark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rUYF7wqmq0uN-FfqGrhUTtyk781aofoU
"""

#!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql import functions as Func

spark = SparkSession.builder \
    .appName("TestandoPySpark") \
    .getOrCreate()

from google.colab import files
uploaded = files.upload()

carros = spark.read.csv("Carros.csv", header=True, sep=";", inferSchema=True)

carros.show(5)
carros.printSchema()
print("Total de linhas:", carros.count())
print("Colunas:", carros.columns)

carros.select("Consumo", "Cilindros").show(5)
carros.select("Consumo", "Cilindros").where(Func.col("Cilindros") > 6).show()
carros.orderBy("HP").show(5)
carros.orderBy(Func.col("HP").desc()).show(5)

#Vamos fazer uma análise mais aprofundada desse pequeno documento

from pyspark.ml.regression import LinearRegression, RandomForestRegressor
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml.feature import VectorAssembler

#Separando as colunas
Carros = carros.select("Consumo", "Cilindros", "Cilindradas", "HP")
Carros.show()

#Vamos vetorizar os atributos
veccaracteristicas = VectorAssembler(inputCols=["Consumo", "Cilindros", "Cilindradas"], outputCol="caracteristicas")
Carros = veccaracteristicas.transform(Carros)
Carros.show()

#Dividindo em treino e teste
CarrosTreino, CarrosTeste = Carros.randomSplit([0.7, 0.3])
print(CarrosTreino.count())
print(CarrosTeste.count())

#Vamos usar LinearRegression
reglin = LinearRegression(featuresCol="caracteristicas", labelCol="HP")
modelo = reglin.fit(CarrosTreino)

#Vamos realizar a previsão
previsao = modelo.transform(CarrosTeste)
previsao.show()

#Avaliando o modelo
avaliar = RegressionEvaluator(predictionCol="prediction", labelCol="HP", metricName="rmse")
rmse = avaliar.evaluate(previsao)
print("RMSE:", rmse)

#O RMSE de 34.18 significa que, em média, as previsões do seu modelo estão 34.18 unidades distantes dos valores reais.

